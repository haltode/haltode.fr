Mars 2016
=========
recap

## Introduction

Durant ce mois de mars, j'ai pu réaliser énormément de choses que je voulais faire durant le mois de février, mais aussi d'autres petits projets plus différents.

## Projet principal

Le gros projet de mars était de commencer à m'intéresser plus sérieusement à l'apprentissage artificiel. J'ai donc suivi le cours en ligne d'Andrew Ng ([Machine Learning](https://www.coursera.org/learn/machine-learning)) que je n'ai pas encore fini mais j'ai actuellement complété 8 des 11 semaines de cours proposées. Cela a pris plus de temps que je ne pensais, et même au rythme de 2h-2h30 par soir c'était assez difficile de vouloir tout compléter en un mois car je n'avais aucunes réelles connaissances dans le domaine du machine learning, ni les connaissances nécessaires en mathématiques pour comprendre le fonctionnement de certains algorithmes. Dans l'ensemble, je trouve que c'est un excellent cours, qui regroupe toutes les notions indispensables pour assimiler (et implémenter) plusieurs algorithmes basiques de machine learning. En revanche, il y a quelques erreurs au niveau des codes sources fournit par le cours (sans doute car il date de 2011, et que le cours n'a pas dû recevoir de mises à jour majeures dans ce domaine récemment), heureusement on trouve rapidement des solutions sur les forums correspondants. Ce qui est important avec ce cours, c'est qu'il propose d'implémenter tous les algorithmes présentés, et recommande pour cela d'utiliser [Octave](https://gnu.org/software/octave/) (une alternative libre et gratuite à Matlab, un langage de programmation interprété et spécialisé dans le calcul numérique), j'ai donc pu découvrir pour la première fois ce langage assez intéressant, surtout pour l'utilisation dans le machine learning qui rend l'implémentation facile avec la plupart des opérateurs mathématiques déjà fournis par le langage.

Ce cours en ligne nécessite pas mal d'investissement, car les semaines sont parfois assez longues, et les vidéos aussi peuvent rapidement dépasser les 15 minutes. Pour essayer de rester concentrer jusqu'au bout, je prenais des notes (j'ai quasiment rempli un cahier de notes), et parfois j'accélérais, voire passais, certains passages.

A noter qu'au même moment, j'ai trouvé une suite de vidéos assez récente permettant d'introduire et d'implémenter un réseau de neurones (en Python cette fois) : [Neural Networks Demystified](http://lumiverse.io/series/neural-networks-demystified). Une approche accessible à tous, et qui permet de mieux comprendre cet algorithme dont on a beaucoup entendu parler, notamment avec la victoire d'[AlphaGo](https://en.wikipedia.org/wiki/AlphaGo) face à Lee Sedol au jeu de Go (comme quoi j'ai bien choisi le mois pour en apprendre plus sur l'apprentissage artificiel !).

## Sous-projet

### mlai

Le cours en ligne de machine learning propose des petits "devoirs" afin d'implémenter des algorithmes d'apprentissage artificiel (ou bien d'autres méthodes spécifiques au domaine). J'ai donc voulu réaliser ces derniers, et proposer ma version des implémentations de différents algorithmes :

- Linear regression
- Logistic regression
- Neural network
- Support vector machines
- K-means

Vous pouvez retrouver toutes les sources du projet sur son repos Github : <https://github.com/napnac/mlai>. Mais il se peut que j'implémente de nouveaux algorithmes dans le futur, notamment car il me reste 3 semaines de cours à compléter.

Les devoirs à faire venant du cours ne sont pas très compliqué vu qu'il suffit dans la plupart du temps d'implémenter les formules données (même s'il faut garder en tête ce que font ces formules pour bien comprendre le but de ce qu'on implémente). En revanche, là où les devoirs sont intéressants c'est qu'on a des données déjà prêtes à être exploitées par notre implémentation (parfois ces données sont inspirées de fait réels : agence immobilière, usine de composants électronique, etc. ou alors elles sont fictives et servent de repères visuelles).

### lispy

Comme autre sous-projet ce mois-ci : [Build Your Own Lisp](http://www.buildyourownlisp.com/). J'ai dû voir ce lien défiler dans mes flux RSS, et j'ai trouvé l'idée intéressante donc j'ai décidé de suivre ce tutoriel, qui un peu à la manière de [Learn Code The Hard Way](http://learncodethehardway.org/), vous apprend à coder un langage de programmation semblable à [Lisp](https://en.wikipedia.org/wiki/Lisp_%28programming_language%29) en C. La lecture était agréable, même si j'ai eu un peu de mal au début ne connaissant pas du tout le Lisp, et j'ai donc du m'adapter à ce nouveau langage.

Vous pouvez retrouver les sources sur le repos du projet : <https://github.com/napnac/lispy>.

## Autres

Entre tout ça, j'ai trouvé le temps d'avancer un peu au niveau des articles :

- J'ai fini l'article sur le [tri par base](/algo/tri/tri_base.html) qui trainait un peu et à moitié fait.
- J'ai aussi terminé la partie sur l'algorithme de Dijkstra dans l'article sur les plus courts chemins. Le texte nécessite cependant encore quelques relectures, et l'article en lui-même est encore loin d'être terminé.
- En voulant commencer la partie sur l'algorithme de Bellman-Ford (toujours dans l'article sur les plus courts chemins), je me suis rendu compte que j'avais envie d'expliquer plus en détails ce qu'était un algorithme dynamique et j'ai donc commencé à rédiger un article expliquant cette approche. Cependant, ceci m'a donné envie de faire de même pour d'autres approches assez utilisées en algorithmique comme : diviser pour régner, récursion, algorithme glouton, etc.

En ce qui concerne les forums, j'ai entrepris d'instaurer un [système de mentorat](https://zestedesavoir.com/forums/sujet/5663/un-systeme-de-mentorat/) sur Zeste de Savoir. L'idée n'a pas forcément très bien accrochée, et j'espère pouvoir relancer le concept (en le modifiant pour qu'ils plaisent à plus de personne) prochainement. 

## Conclusion

Le mois de mars c'est surtout un bon rattrapage face au mois de février, et j'ai adoré faire toutes ces activités assez différentes (entre le machine learning, lispy, les articles et Zeste de Savoir). Durant le mois d'avril j'aimerais donc finir le cours d'Andrew Ng, mais surtout écrire des articles à propos des différents algorithmes de machine learning que j'ai appris (car le fait d'expliquer permet de se rendre compte si on a réellement compris), et si possible je souhaiterais faire un projet concret incluant de l'apprentissage artificiel (même si je n'ai pas encore d'idée). Aussi, j'adorerais réaliser un défi de Clem' sur Zeste de Savoir qui consisterait en une série de petits challenges divers (j'évoque l'idée [ici](https://zestedesavoir.com/forums/sujet/3813/les-defis-de-clem/?page=11#p102365)).

Je pense qu'avril sera le dernier mois réellement dédié au machine learning, après cela je vais passer à autre chose.

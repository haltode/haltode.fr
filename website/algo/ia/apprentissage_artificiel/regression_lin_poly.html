<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8">

      <!-- CSS -->
      <link rel="stylesheet" type="text/css" href="/css/default.css">
      <link rel="stylesheet" type="text/css" href="/css/highlight_theme.css">

      <!-- Icon -->
      <link rel="icon" type="image/x-icon" href="/img/favicon.ico">

      <!-- Syntax highlighting -->
      <script src="/js/highlight.pack.js"></script>
      <script>hljs.initHighlightingOnLoad();</script>

      <!-- Renders LaTeX expression -->
      <script type="text/x-mathjax-config">
         MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
      </script>
      <script type="text/javascript" async 
              src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
      </script>

      <title>Régression linéaire/polynomiale - napnac</title>
   </head>

   <body>
      <header>
         <a href="/">
            <img src="/img/logo.png" alt="Logo du site" height="100" width="300">
         </a>
      </header>

      <nav>
         <ul id="main_menu">
            <li><a href="/">Accueil</a></li>
            <li><a href="/articles.html">Articles</a></li>
            <li><a href="/projets.html">Projets</a></li>
            <li><a href="/a_propos.html">A propos</a></li>
         </ul>
      </nav>

      

<a href=""><h1>Régression linéaire/polynomiale</h1></a>

<p>Publié le : 25/04/2016</p>
<p>Modifié le : 25/04/2016</p>

<h2>Introduction</h2>
<p>Vous souhaitez estimer le prix d&rsquo;un ordinateur en fonction de différents facteurs (puissance, mémoire, stockage, batterie, etc.), cependant la tâche se complique au fur et à mesure que vous rajoutez des possibilités, et vous décidez alors d&rsquo;employer un algorithme d&rsquo;apprentissage artificiel pour faire le travail à votre place. Afin de prendre un exemple simple, on va dire que vous estimez le prix d&rsquo;un ordinateur uniquement en fonction de sa puissance de calcul. Dans l&rsquo;<a href="/algo/ia/apprentissage_artificiel/introduction.html">introduction à la matière</a>, on a vu que récolter des données utiles est une étape importante dans un processus d&rsquo;apprentissage, et vous avez alors noté la puissance et le prix de différents ordinateurs dans un tableau :</p>
<p><em>Les données sont totalement inventées et ne servent que d&rsquo;exemple.</em></p>
<table>
<thead>
<tr>
<th>Puissance (nombre d&rsquo;opérations/s)</th>
<th>Prix (€)</th>
</tr>
</thead>
<tbody>
<tr>
<td>173</td>
<td>194</td>
</tr>
<tr>
<td>407</td>
<td>287</td>
</tr>
<tr>
<td>534</td>
<td>501</td>
</tr>
<tr>
<td>714</td>
<td>674</td>
</tr>
<tr>
<td>956</td>
<td>771</td>
</tr>
<tr>
<td>1226</td>
<td>860</td>
</tr>
</tbody>
</table>
<p>On peut représenter ce tableau grâce à un graphique en deux dimensions très simple :</p>
<figure><img alt="Exemple de données récoltées" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_donnees.png" /><figcaption>Exemple de données récoltées</figcaption>
</figure>
<p>Ce qu&rsquo;on cherche à faire dans notre problème c&rsquo;est d&rsquo;<strong>extrapoler</strong>, c&rsquo;est-à-dire généraliser grâce aux données obtenues afin de prédire un résultat. En tant qu&rsquo;humain, on pourrait facilement faire une bonne généralisation comme ceci :</p>
<figure><img alt="Exemple de généralisation" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_generalisation.png" /><figcaption>Exemple de généralisation</figcaption>
</figure>
<p>On a une fonction linéaire basique, qu&rsquo;on peut ensuite utiliser graphiquement pour trouver à partir de la puissance d&rsquo;un ordinateur, une bonne estimation de son prix.</p>
<p>Cependant, du point de vue d&rsquo;une personne, il est facile de trouver un lien entre les données dans le but de généraliser, mais comment un algorithme peut-il reproduire ce comportement ? Qu&rsquo;est-ce qui fait qu&rsquo;une fonction (linéaire, polynomiale, etc.) est une bonne généralisation de notre problème ?</p>
<p>Avant de se lancer dans la recherche d&rsquo;un algorithme d&rsquo;apprentissage artificiel, il faut définir ses caractéristiques. Dans notre problème, on a un ensemble de données sous la forme d&rsquo;entrées et de sorties correspondantes, nous sommes donc dans un <strong>apprentissage supervisé</strong>. De plus, la sortie qu&rsquo;on cherche est une valeur numérique, notre problème appartient alors au domaine de la <strong>régression</strong>. Une fois qu&rsquo;on connaît ces deux informations essentielles, on peut décider de l&rsquo;algorithme à utiliser en fonction de nos besoins et de nos ressources. Dans notre situation on souhaiterait faire une généralisation sous la forme d&rsquo;une fonction linéaire, la méthode à employer est donc : la <strong>régression linéaire</strong>.</p>
<p><em>La régression linéaire n&rsquo;est qu&rsquo;un cas particulier de la régression polynomiale, mais il est plus simple de commencer avec une simple fonction linéaire pour ensuite aborder des fonctions plus complexes (même si le principe reste exactement le même).</em></p>
<h2>Principe</h2>
<p>La régression linéaire est un moyen de généraliser et de créer un modèle linéaire à partir d&rsquo;exemples. Lesdits exemples sont représentés à l&rsquo;aide de <a href="https://en.wikipedia.org/wiki/Matrix_%28mathematics%29">matrices</a> où $x$ est l&rsquo;entrée, et $y$ est la sortie correspondante. Prenons le cas où on essaie de généraliser le prix d&rsquo;un appartement en fonction de sa taille et de son nombre de pièces (encore une fois les données sont fictives):</p>
<table>
<thead>
<tr>
<th>Taille (m²)</th>
<th>Nombre de pièces</th>
<th>Prix (millier €)</th>
</tr>
</thead>
<tbody>
<tr>
<td>112</td>
<td>4</td>
<td>253</td>
</tr>
<tr>
<td>203</td>
<td>6</td>
<td>760</td>
</tr>
<tr>
<td>158</td>
<td>5</td>
<td>558</td>
</tr>
<tr>
<td>98</td>
<td>3</td>
<td>243</td>
</tr>
<tr>
<td>143</td>
<td>4</td>
<td>302</td>
</tr>
</tbody>
</table>
<p>Nos matrices ressembleront à ceci :</p>
<p>$x = \begin{bmatrix} 112 &amp; 4 \ 203 &amp; 6 \ 158 &amp; 5 \ 98 &amp; 3 \ 143 &amp; 4 \end{bmatrix}$ $y = \begin{bmatrix} 253 \ 760 \ 558 \ 243 \ 302 \end{bmatrix}$</p>
<p>Le <strong>modèle</strong> qu&rsquo;on cherche à construire est une fonction linéaire, qu&rsquo;on notera :</p>
<p>$h_{\theta}(x) = \theta_{0} + \theta_{1}x_1 + \theta_{2}x_2 + \ldots + \theta_{n}x_n$</p>
<p>$\theta$ correspond aux coefficients de notre fonction qui prend $n$ <strong>attributs</strong> (ou <em>feature</em> en anglais). Les attributs sont les différentes colonnes de $x$ (la puissance d&rsquo;un ordinateur, la taille d&rsquo;un appartement, le nombre de pièces, etc.) et c&rsquo;est sur quoi se base l&rsquo;algorithme pour généraliser le problème qu&rsquo;on lui donne. Il est très important de bien choisir les attributs, et de renseigner uniquement ceux qui ont une réelle influence sur le résultat, mais sans pour autant en donner trop peu à l&rsquo;algorithme.</p>
<p>On souhaite donc trouver une fonction $h_{\theta}$, aussi appelée <strong>fonction d&rsquo;hypothèse</strong>, tel que $h(x) \simeq y$. Le problème que cherche à résoudre la régression linéaire est de trouver les paramètres $\theta$ qui rendent notre modèle proche de la réalité (représentée par $y$) afin qu&rsquo;il soit efficace.</p>
<p>Si l&rsquo;on reprend notre énoncé de départ sur le prix d&rsquo;un ordinateur, on a uniquement un attribut (sa puissance), et on cherche une estimation du prix à l&rsquo;aide d&rsquo;une fonction d&rsquo;hypothèse de la forme :</p>
<p>$h_{\theta}(x) = \theta_{0} + \theta_{1}x_1$</p>
<p>Mais pour comprendre comment trouver un bon modèle, il faut tout d&rsquo;abord comprendre comment décrire l&rsquo;efficacité d&rsquo;un modèle quelconque, et surtout qu&rsquo;est-ce qui rend un modèle meilleur qu&rsquo;un autre ?</p>
<h2>Fonction d&rsquo;erreur</h2>
<p>Afin de différencier deux modèles en fonction de leurs efficacités, on va utiliser une <strong>fonction d&rsquo;erreur</strong> qui mesure le taux d&rsquo;erreur entre notre modèle et la réalité.</p>
<p>Si on prend un exemple $i$, la différence entre l&rsquo;estimation de notre fonction d&rsquo;hypothèse et la sortie fournie en entrée se note :</p>
<p>$h_{\theta}(x_{i}) - y_{i}$</p>
<p>Où $x_{i}$ et $y_{i}$ désignent le $i$ème exemple sous la forme d&rsquo;un couple (entrée, sortie). Cependant, cette valeur peut être négative, on va donc la monter au carré car cela nous permet aussi d&rsquo;amplifier le résultat (s&rsquo;il y a une grosse différence, alors le carré produira un résultat très élevé et inversement). Si on avait utilisé une autre fonction pour rendre l&rsquo;expression positive, comme la <a href="https://en.wikipedia.org/wiki/Absolute_value">valeur absolue</a>, on n&rsquo;aurait pas eu cette deuxième propriété intéressante qui permet de mieux distinguer deux modèles en fonction de leurs efficacités.</p>
<p>$(h_{\theta}(x_{i}) - y_{i})^2$</p>
<p>Vu qu&rsquo;il y a $m$ exemples en entrée, on va faire la moyenne de toutes les différences au carré pour prendre chaque exemple en compte dans notre fonction d&rsquo;erreur :</p>
<p>$\frac{1}{m} \displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})^2$</p>
<p>Si on reprend la généralisation qu&rsquo;on a faite à la main, la différence que l&rsquo;on calcule dans notre expression correspond aux parties vertes sur ce schéma :</p>
<figure><img alt="Exemple de calcul de différence entre estimation et réalité" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_calcul_erreur.png" /><figcaption>Exemple de calcul de différence entre estimation et réalité</figcaption>
</figure>
<p>On notera cette fonction $J$, qu&rsquo;on appelle aussi l&rsquo;<strong>estimateur des moindres carrés</strong> :</p>
<p>$J(\theta) = \frac{1}{m} \displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})^2$</p>
<p>Par convention, et pour simplifier nos futurs calculs, on divise le résultat obtenu par 2 :</p>
<p>$J(\theta) = \frac{1}{2m} \displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})^2$</p>
<p>Cette fonction d&rsquo;erreur nous permet alors de comparer deux modèles en fonction des paramètres $\theta$ qu&rsquo;ils utilisent. Il est d&rsquo;ailleurs possible de démontrer que cette fonction est un estimateur optimal sous certaines hypothèses grâce au <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem">théorème de Gauss-Markov</a>, c&rsquo;est pour cela qu&rsquo;elle est utilisée quasiment dans tous les cas de régression linéaire/polynomiale.</p>
<p>Grâce à cela, on peut enfin définir concrètement ce que signifie &ldquo;trouver le meilleur modèle&rdquo;. Cela revient à trouver des paramètres $\theta$ qui <strong>minimisent</strong> la fonction d&rsquo;erreur utilisée.</p>
<p>Si l&rsquo;on affiche graphiquement la fonction d&rsquo;erreur pour notre problème, on obtient ceci :</p>
<figure><img alt="Exemple de représentation graphique de la fonction d'erreur" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_fonction_erreur.png" /><figcaption>Exemple de représentation graphique de la fonction d&rsquo;erreur</figcaption>
</figure>
<p>Sur ce graphique représentant $J$ en fonction de $\theta_{0}$ et $\theta_{1}$, on remarque clairement les valeurs de $\theta$ pour lesquelles la fonction d&rsquo;erreur est minimisée. Cependant, il va falloir trouver un algorithme qui calcule ces valeurs automatiquement, car on ne pourra pas toujours faire de représentation graphique (lorsqu&rsquo;on a beaucoup d&rsquo;attributs en entrée par exemple).</p>
<h2>Algorithmes</h2>
<p>On a réussi à définir mathématiquement l&rsquo;objectif de la régression linéaire grâce à notre fonction d&rsquo;erreur. Désormais il faut donc minimiser cette fonction avec les paramètres $\theta$.</p>
<p>Deux méthodes répandues s&rsquo;offrent à nous :</p>
<ul>
<li><a href="/algo/ia/apprentissage_artificiel/regression_lin_poly/algo_gradient.html"><strong>L&rsquo;algorithme du gradient</strong></a> (<em>gradient descent</em> en anglais) : un algorithme itératif utile quand $n$ est très large, et personnalisable grâce à un coefficient d&rsquo;apprentissage (ce dernier peut aussi être un désavantage car dans certains cas il est difficile de le choisir efficacement).</li>
<li><a href="/algo/ia/apprentissage_artificiel/regression_lin_poly/equation_normale.html"><strong>L&rsquo;équation normale</strong></a> : une équation donnant le résultat directement sans itérations, cependant cette dernière est très lourde en opérations à cause du <a href="https://en.wikipedia.org/wiki/Matrix_multiplication">produit matriciel</a> qui a une complexité en temps de $O(n^3)$. On l&rsquo;utilisera plutôt quand $n$ est suffisamment petit (en général en dessous de 10000).</li>
</ul>
<h2>Régression polynomiale</h2>
<p>Maintenant qu&rsquo;on a vu comment fonctionne la régression linéaire, il est temps d&rsquo;utiliser des fonctions polynomiales plus complexes afin de généraliser sur des données non linéaires. En réalité, l&rsquo;unique changement à réaliser est sur notre fonction d&rsquo;hypothèse puisque la fonction d&rsquo;erreur et les deux algorithmes restent exactement les mêmes. Il suffit donc d&rsquo;employer une <strong>fonction d&rsquo;hypothèse polynomiale</strong> :</p>
<p>$h_{\theta}(x) = \theta_{0} + \theta_{1}x_1 + \theta_{2}x_2^2 + \ldots + \theta_{n}x_n^d$</p>
<p>Dans cette expression, $d$ correspond au degré maximum de notre fonction.</p>
<p>Dans le cas où on a peu d&rsquo;attributs, et qu&rsquo;on veut une fonction très complexe, il est tout à fait possible d&rsquo;utiliser plusieurs fois les mêmes attributs mais avec différents degrés, par exemple :</p>
<p>$h_{\theta}(x) = \theta_{0} + \theta_{1}x_1 + \theta_{2}x_1^2 + \theta_{3}x_1^3$</p>
<p>Il est aussi courant d&rsquo;ajouter d&rsquo;autres termes que de simples puissances, comme des exponentiations, des logarithmes, des racines carrées, des fonctions trigonométriques, etc. dans le but de modéliser des fonctions avec un aspect particulier pour bien coller à nos données.</p>
<p>Si possible, afficher les données sur un graphique est la meilleure chose à faire afin de pouvoir visualiser quels types d&rsquo;attributs il nous faut pour notre fonction d&rsquo;hypothèse. Sinon, il est toujours envisageable de tester plusieurs combinaisons et de voir laquelle est la meilleure en fonction du résultat de la fonction d&rsquo;erreur.</p>
<figure><img alt="Exemple de régression polynomiale sur des données non-linéaires" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_regression_polynomiale.png" /><figcaption>Exemple de régression polynomiale sur des données non-linéaires</figcaption>
</figure>
<h2>Problèmes</h2>
<p>Dans le domaine de l&rsquo;apprentissage artificiel, il y a un problème commun à de très nombreux algorithmes : le <strong>surapprentissage</strong>.</p>
<p>Dans un apprentissage supervisé, le but est de fournir à notre algorithme des exemples à partir desquels il peut généraliser le problème à résoudre. Cependant, il arrive que ce dernier ne généralise pas assez, et en vient à réciter par cœur les données fournies. Le problème est que notre programme va alors trouver la bonne réponse sur quasiment tous nos exemples, mais dès qu&rsquo;il verra une nouvelle entrée il répondra totalement à côté. Il n&rsquo;a pas réussi à généraliser, et il est tombé dans le cas par cas. Cette notion de surapprentissage (ou <em>overfitting</em> en anglais) est essentielle à comprendre car c&rsquo;est un problème extrêmement récurrent dans le domaine de l&rsquo;apprentissage artificiel, et spécialement dans le cadre d&rsquo;un apprentissage supervisé.</p>
<p>Par exemple, prenons des données imaginaires :</p>
<figure><img alt="Exemple de données" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_donnees_vide.png" /><figcaption>Exemple de données</figcaption>
</figure>
<p>On pourrait tenter d&rsquo;utiliser une régression linéaire avec une fonction d&rsquo;hypothèse de la forme $h_{\theta}(x) = \theta_0 + \theta_1x_1$ :</p>
<figure><img alt="Tentative de régression linéaire" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_sousapprentissage.png" /><figcaption>Tentative de régression linéaire</figcaption>
</figure>
<p>On voit bien qu&rsquo;on arrive à une très mauvaise généralisation car il nous manque des attributs. Dans ce cas, on parle de <strong>sous-apprentissage</strong> (ou <em>underfitting</em> en anglais), c&rsquo;est une situation plus rare que le surapprentissage, et il suffit de rajouter des attributs pour contrer le problème. Essayons, avec une simple fonction polynomiale comme $h_{\theta}(x) = \theta_0 + \theta_1x_1 + \theta_2x_1^2$ :</p>
<figure><img alt="Une simple fonction polynomiale" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_regression_polynomiale.png" /><figcaption>Une simple fonction polynomiale</figcaption>
</figure>
<p>Notre modèle polynomial correspond bien à nos données et semble assez bien généraliser le problème. Cependant, que se passe-t-il si on avait rajouté plus d&rsquo;attributs ? Essayons avec une fonction polynomiale plus complexe comme $h_{\theta}(x) = \theta_0 + \theta_1x_1 + \theta_2x_1^2 + \theta_3x_1^3 + \theta_4x_1^4 \ldots$ :</p>
<figure><img alt="Fonction polynomiale très complexe" src="/img/algo/ia/apprentissage_artificiel/regression_lin_poly/exemple_surapprentissage.png" /><figcaption>Fonction polynomiale très complexe</figcaption>
</figure>
<p>Le modèle essaie de coller au mieux à nos données au point de ne plus du tout généraliser le problème, on est tombé dans le surapprentissage. Notre programme s&rsquo;est trop bien adapté à nos données, et il n&rsquo;arrivera pas à prédire correctement la sortie de nouveaux exemples.</p>
<p>L&rsquo;apprentissage supervisé est donc un domaine difficile car il faut arriver à trouver les attributs vraiment nécessaires à notre algorithme pour être le plus efficace possible, sans pour autant tomber dans le surapprentissage. Mais il existe des méthodes afin d&rsquo;éviter au plus ce problème si contraignant, comme la <strong>régularisation</strong>.</p>
<h3>Régularisation</h3>
<p>Le principe de la régularisation est de <strong>pénaliser</strong> les attributs avec des coefficients ayant des degrés élevés (puisque c&rsquo;est à cause d&rsquo;eux que notre modèle a une forme très particulière qui ne généralise pas assez). Si l&rsquo;on reprend notre dernier exemple avec une fonction d&rsquo;hypothèse de la forme :</p>
<p>$h_{\theta}(x) = \theta_0 + \theta_1x_1 + \theta_2x_1^2 + \theta_3x_1^3 + \theta_4x_1^4 \ldots$</p>
<p>Pénaliser $\theta_3$ et $\theta_4$ permettrait d&rsquo;avoir un modèle qui généralise beaucoup mieux, sans passer par des formes extrêmes.</p>
<p>Pour réaliser cela, il faut ajouter à notre fonction d&rsquo;erreur un terme de régularisation :</p>
<p>$J(\theta) = \frac{1}{2m} \left[\displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})^2 + \lambda \displaystyle\sum_{j=1}^{n} \theta_j^2\right]$</p>
<p>Dans le terme ajouté $\lambda \displaystyle\sum_{j=1}^{n} \theta_j^2$, on a $\lambda$ qui correspond au <strong>paramètre de la régularisation</strong> (et donc qui détermine la puissance de la pénalisation). Il faut aussi noter qu&rsquo;on ne pénalise pas $\theta_0$.</p>
<p>Grâce à cela, les coefficients avec des degrés élevés augmenteront fortement le résultat de la fonction d&rsquo;erreur, obligeant naturellement à nos algorithmes de pénaliser ces derniers. On arrive donc à une fonction d&rsquo;hypothèse simplifiée, et moins sujet au cas de surapprentissage.</p>
<p>Cependant il faut adapter nos deux algorithmes à cette nouvelle fonction d&rsquo;erreur, en les modifiant légèrement.</p>
<h4>Algorithme du gradient</h4>
<p>Avec notre ancienne fonction d&rsquo;erreur, on devait mettre à jour nos coefficients de manière simultanée de cette façon (si l&rsquo;on n&rsquo;utilise pas la version vectorisée) :</p>
<p>Pour chaque coefficient $\theta_j$ avec $j$ allant de 0 à $n$ :</p>
<p>$\theta_{j} = \theta_{j} - \alpha\frac{1}{m}\displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})x_{ij}$</p>
<p>Désormais, on va avoir :</p>
<p>Pour chaque coefficient $\theta_j$ avec $j$ allant de 1 à $n$ (puisqu&rsquo;on ne pénalise pas $\theta_0$, et on utilisera l&rsquo;ancienne formule pour ce coefficient) :</p>
<p>$\theta_{j} = \theta_{j} - \alpha\left[\frac{1}{m}\displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})x_{ij} + \frac{\lambda}{m}\theta_j\right]$</p>
<p>On a obtenu cette formule de la même manière que pour l&rsquo;ancienne, c&rsquo;est-à-dire en calculant la dérivée partielle de la fonction d&rsquo;erreur.</p>
<h4>Equation normale</h4>
<p>Pour l&rsquo;équation normale, on applique de nouveau notre démonstration mais sur notre nouvelle fonction d&rsquo;erreur, ce qui nous donne le résultat suivant :</p>
<p>$\theta = \left(x^\intercal x + \lambda \left[\begin{smallmatrix} 0\ &amp;1\ &amp;&amp;1 \ &amp;&amp;&amp;\ddots \ &amp;&amp;&amp;&amp;1 \end{smallmatrix}\right]\right)^{-1} x^\intercal y$</p>
<p>On retrouve notre paramètre de régularisation $\lambda$, ainsi qu&rsquo;une matrice de taille $(n + 1)\times(n + 1)$ assez spéciale composée de 1 uniquement dans la diagonale en partant de la deuxième colonne (le reste de la matrice contient des 0). Cette matrice est en réalité une <a href="https://en.wikipedia.org/wiki/Identity_matrix">matrice identité</a> sans le premier terme en haut à gauche (en rapport avec $\theta_0$ qui n&rsquo;est pas pénalisé).</p>
<h4>Paramètre de régularisation</h4>
<p>Avec un paramètre $\lambda$ très large, on tombe dans le cas du sous-apprentissage car nos coefficients seront tellement pénalisés qu&rsquo;on risque d&rsquo;avoir une fonction d&rsquo;hypothèse trop simple pour notre problème. A l&rsquo;inverse, un paramètre $\lambda$ trop petit ne va pas assez pénaliser les coefficients avec des degrés élevés ce qui n&rsquo;atténuera pas notre problème de surapprentissage et sera donc inutile.</p>
<p>Il faut alors réussir à choisir un bon paramètre de régularisation $\lambda$, et pour cela on peut s&rsquo;aider de différents échantillons, ainsi que de la <strong>validation croisée</strong>. Jusqu&rsquo;à présent, le seul échantillon de nos données qu&rsquo;on utilisait était <strong>l&rsquo;échantillon d&rsquo;apprentissage</strong>. On va désormais rajouter deux nouveaux échantillons :</p>
<ul>
<li><strong>l&rsquo;échantillon de test</strong> : on l&rsquo;utilisera pour mesurer l&rsquo;efficacité de notre algorithme sur de nouvelles données, car si on mesure cela sur notre échantillon d&rsquo;apprentissage et que notre algorithme a un problème de surapprentissage, on verra de très bons résultats alors qu&rsquo;on a un programme médiocre incapable de généraliser.</li>
<li><strong>l&rsquo;échantillon de validation</strong> : on va employer cet échantillon afin de tester différentes valeurs de $\lambda$ et sélectionner la meilleure.</li>
</ul>
<p>On n&rsquo;utilisera pas l&rsquo;échantillon de test dans le choix du paramètre $\lambda$, mais il est important d&rsquo;en parler car en général sur nos données on les divise entre nos différents échantillons de tel sorte à avoir environ 60% des données dans l&rsquo;échantillon d&rsquo;apprentissage, 20% dans celui de test, et 20% dans celui de validation.</p>
<p>Le principe de la validation croisée est de tester différentes valeurs de $\lambda$ et sélectionner la meilleure grâce à notre fonction d&rsquo;erreur et à nos échantillons :</p>
<ul>
<li>Générer différents paramètres de régularisation (0, 0.01, 0.02, 0.04, &hellip;, 1, &hellip; 10, &hellip;).</li>
<li>Pour chaque paramètre $\lambda$ à tester, calculer les coefficients $\theta$ en minimisant $J$ (version régularisée).</li>
<li>Pour chaque coefficient obtenu, calculer le taux d&rsquo;erreur par rapport à notre échantillon de validation (encore inconnue du programme) en utilisant la fonction d&rsquo;erreur non régularisée sur cet échantillon : $J_{validation}$ (on n&rsquo;utilise pas l&rsquo;échantillon de test car il ne faut pas que notre algorithme voit les données de cet échantillon avant d&rsquo;être totalement entrainé).</li>
<li>Choisir $\lambda$ qui obtient le plus faible taux d&rsquo;erreur sur la dernière étape.</li>
</ul>
<p>Notez qu&rsquo;on peut utiliser cette méthode de validation croisée afin de choisir les degrés à utiliser dans notre fonction d&rsquo;hypothèse polynomiale de la même façon que pour $\lambda$.</p>
<h2>Conclusion</h2>
<p>La régression linéaire/polynomiale est donc un moyen de généraliser un problème à partir d&rsquo;exemples fournis en construisant un modèle plus ou moins complexe. On a pu voir deux algorithmes très différents, ainsi que le principal problème lié à ce type d&rsquo;apprentissage avant d&rsquo;aborder une solution efficace.</p>
<p>Même si l&rsquo;action de &ldquo;généraliser&rdquo; est une notion assez facile à appréhender en tant qu&rsquo;humain, c&rsquo;est bien plus compliqué de le faire comprendre à un ordinateur et les mathématiques nous permettent de nous en rapprocher considérablement comme on a pu le voir. L&rsquo;algorithme du gradient sera d&rsquo;ailleurs utilisé à travers d&rsquo;autres algorithmes d&rsquo;apprentissage artificiel, il était donc important de le découvrir ici dans un cadre assez accessible.</p>
<p>Déduire un modèle à partir de données est un problème très commun, et la régression linéaire/polynomiale est une méthode employée dans pleins de domaines comme l&rsquo;économie, la finance, les statistiques, la géographie, la physique, la biologie, etc.</p>



      <footer>
         <br>
         <hr>
         <p>Une question ? Une suggestion ? N'hésitez pas à me <a href="/a_propos.html">contacter</a> pour me communiquer vos remarques.</p>
         <br>
      </footer>

   </body>
</html>
<!DOCTYPE html>
<html>
   <head>
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato&#38;subset=latin,latin-ext" type="text/css" />
      <link rel="icon" type="image/x-icon" href="//static.napnac.ga/img/favicon.ico">
      <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.8.0/styles/github-gist.min.css">

      <!-- Syntax highlighting -->
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.8.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script>

      <!-- Renders LaTeX expression -->
      <script type="text/x-mathjax-config">
         MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
      </script>
      <script type="text/javascript" async
         src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
      </script>

      <!-- CSS -->
<style>
body {
   font-family: "Helvetica Neue", 'Lato', Helvetica, sans-serif;
   max-width: 1000px;
   margin: 0 auto;
   position: relative;
   width: 95%;
   line-height: 1.5;
}

/* ---- Titles ---- */

h1 {
   padding-top: 2%;
   padding-bottom: 2%;
   color: #DE4834;
}

h2, h3, h4, h5, h6 {
   padding-top: 1%;
   padding-bottom: 1%;
   color: #DE4834;
}

/* ---- Link ---- */

a {
   text-decoration: none;
   color: #2E64FE;
}

/* ---- List (+ main menu list) ---- */

ul {
   padding-left: 30px;
}

#main_menu {
   list-style: none;
   margin: 0;
   padding: 0;
   text-align: center;
}
#main_menu li {
   display: inline;
   margin-right: 1px;
}
#main_menu li a {
   line-height: 1em;
   padding: 4px 20px;
   text-align: center;
}
#main_menu li a:hover, #main_menu li a:active {
   text-decoration: underline;
}

/* ---- Tables (same look as from github markdown layout) ---- */

table {
   display: block;
   width: 100%;
   overflow: auto;
   word-break: normal;
   word-break: keep-all;
   border-collapse: collapse;
   border-spacing: 0;
   margin-top: 0;
   margin-bottom: 16px;
}

table th {
   font-weight: bold;
}

table th,
table td {
   padding: 6px 13px;
   border: 1px solid #ddd;
}

table tr {
   background-color: #fff;
   border-top: 1px solid #ccc;
}

table tr:nth-child(2n) {
   background-color: #f8f8f8;
}

/* ---- Image and caption ---- */

.figure {
   text-align: center;
}

.caption {
   font-style: italic;
   text-align: center;
}

/* ---- Summary ---- */

#summary {
   width: 70%;
   text-align: justify;
   line-height: 1.6;
}

/* ---- Code ---- */
pre {
   width: 90%;
   white-space: pre-wrap;
   word-break: break-all;
   word-wrap: break-word;
}
</style>
      <!---- ---->

      <title>Algorithme du gradient - napnac</title>
   </head>

   <body>

      <!-- Javascript -->
<script type="text/javascript">
function toggle_visibility(id) {
   var element = document.getElementById(id);
   if(element.style.display == 'block')
      element.style.display = 'none';
   else
      element.style.display = 'block';
}
</script>
      <!---- ---->

      <header>
         <a href="/">
            <img src="//static.napnac.ga/img/logo.png" alt="Logo du site" height="100" width="300">
         </a>

      </header>

      <nav>
         <ul id="main_menu">
            <li><a href="/">Accueil</a></li>
            <li><a href="/articles.html">Articles</a></li>
            <li><a href="/projets.html">Projets</a></li>
            <li><a href="/a_propos.html">A propos</a></li>
         </ul>
      </nav>

      <!-- Page/Article -->

<a href=""><h1 id="algorithme-du-gradient">Algorithme du gradient</h1></a>
<p>Publi&#233; le : 19/04/2016<br />
<em>Modifi&#233; le : 19/04/2016</em></p>
<ul id="summary">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#principe">Principe</a></li>
<li><a href="#pseudo-code">Pseudo-code</a></li>
<li><a href="#coefficient-dapprentissage">Coefficient d'apprentissage</a></li>
<li><a href="#impl&#233;mentation">Impl&#233;mentation</a></li>
<li><a href="#am&#233;liorations">Am&#233;liorations</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2 id="introduction">Introduction</h2>
<p>Dans le cadre d'une <a href="/algo/ia/apprentissage_artificiel/regression_lineaire.html">r&#233;gression lin&#233;aire</a>, on cherche &#224; d&#233;finir une fonction d'hypoth&#232;se proche de la r&#233;alit&#233; et de la forme :</p>
<p><span class="math inline">\(h_{\theta}(x) = \theta_{0} + \theta_{1}x_1 + \theta_{2}x_2 + \ldots + \theta_{n}x_n\)</span></p>
<p>Par convention et pour simplifier le code, il n'est pas rare de rajouter un attribut <span class="math inline">\(x_0 = 1\)</span>, afin de remplacer notre fonction par :</p>
<p><span class="math inline">\(h_{\theta}(x) = \displaystyle\sum_{i=0}^{n} \theta_{i}x_{i}\)</span></p>
<p>Cependant, <span class="math inline">\(\theta\)</span> et <span class="math inline">\(x\)</span> sont deux matrices, et le calcul de la fonction d'hypoth&#232;se pourrait s'&#233;crire sous la forme d'un simple <a href="https://en.wikipedia.org/wiki/Matrix_multiplication">produit matriciel</a> :</p>
<p><span class="math inline">\(h_{\theta}(x) = \theta^\intercal x = x \theta\)</span></p>
<p>Or on cherche &#224; trouver une fonction d'hypoth&#232;se efficace, et ceci revient &#224; trouver les coefficients <span class="math inline">\(\theta\)</span> de <span class="math inline">\(h_{\theta}\)</span> qui minimisent la fonction d'erreur <span class="math inline">\(J\)</span>. Pour rappel, notre fonction d'erreur ressemble &#224; cela :</p>
<p><span class="math inline">\(J(\theta) = \frac{1}{2m} \displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})^2\)</span></p>
<p>Et si on reprend l'exemple du prix de l'ordinateur, et qu'on affiche <span class="math inline">\(J\)</span> en fonction de <span class="math inline">\(\theta_0\)</span> et <span class="math inline">\(\theta_1\)</span>, on obtenait ce graphique en trois dimensions :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/exemple_fonction_erreur.png" alt="Repr&#233;sentation graphique de la fonction d&#39;erreur" />
<p class="caption">Repr&#233;sentation graphique de la fonction d'erreur</p>
</div>
<p>On va donc appliquer notre algorithme du gradient (<em>gradient descent</em> en anglais) afin de r&#233;soudre notre probl&#232;me de minimisation.</p>
<h2 id="principe">Principe</h2>
<p>L'id&#233;e de l'algorithme est de commencer avec des param&#232;tres initiaux <span class="math inline">\(\theta\)</span> (en g&#233;n&#233;ral on utilise 0), puis d'adapter ces derniers avec le r&#233;sultat obtenu par notre fonction d'erreur, afin de minimiser <span class="math inline">\(J\)</span> et arriver &#224; un <strong>minimum local</strong>. Il est possible que ce minimum local, soit le <strong>minimum global</strong> de notre fonction d'erreur, mais l'algorithme ne le garantit pas car le r&#233;sultat d&#233;pendra de l'initialisation des coefficients <span class="math inline">\(\theta\)</span>.</p>
<p>Il est plus difficile de visualiser l'id&#233;e de l'algorithme sur notre pr&#233;c&#233;dent graphique en 3D, alors on va utiliser un graphique 2D sp&#233;cial qui trace les contours (on appelle cela un <a href="http://www.itl.nist.gov/div898/handbook/eda/section3/contour.htm"><em>contour plot</em></a> en anglais) :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/contour_plot.png" alt="Contour plot de notre graphique" />
<p class="caption">Contour plot de notre graphique</p>
</div>
<p>Les contours repr&#233;sentent <span class="math inline">\(J\)</span> en fonction de nos deux coefficients <span class="math inline">\(\theta_{0}\)</span> et <span class="math inline">\(\theta_{1}\)</span>. La croix rouge correspond au minimum de la fonction d'erreur, et c'est le point qu'on cherche &#224; atteindre.</p>
<p>L'algorithme du gradient va proc&#233;der ainsi :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/exemple_algo_gradient.png" alt="Exemple du fonctionnement de l&#39;algorithme du gradient" />
<p class="caption">Exemple du fonctionnement de l'algorithme du gradient</p>
</div>
<p>On part d'un point initial sur le graphique, et on fait des pas de plus en plus petits afin de se rapprocher du minimum de la fonction. Cependant, comment l'algorithme r&#233;alise-t-il ces pas ? Comment est-ce qu'il d&#233;cide de l'amplitude, ou encore de la direction &#224; emprunter ?</p>
<p>Pour comprendre l'algorithme, on peut imaginer que ce dernier utilise la &quot;pente&quot; de la repr&#233;sentation de la fonction pour d&#233;cider du prochain point &#224; explorer. Par exemple sur notre graphique en 3D, il suffit d'imaginer une boule qu'on place sur la figure et qui va rouler jusqu'&#224; arriver dans un creux ou une surface assez plane. Math&#233;matiquement parlant, la d&#233;cision du prochain point &#224; parcourir se fera gr&#226;ce &#224; la <a href="https://en.wikipedia.org/wiki/Partial_derivative"><strong>d&#233;riv&#233;e partielle</strong></a> de la fonction <span class="math inline">\(J\)</span> au point actuel de notre algorithme.</p>
<p>Simplifions notre probl&#232;me avec un exemple de fonction <span class="math inline">\(J\)</span> prenant uniquement un param&#232;tre <span class="math inline">\(\theta_{0}\)</span> :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/exemple_simplifie_algo_gradient.png" alt="Exemple simplifi&#233; de l&#39;algorithme du gradient" />
<p class="caption">Exemple simplifi&#233; de l'algorithme du gradient</p>
</div>
<p>On initialise l'algorithme avec un point tel que <span class="math inline">\(\theta_{0} = 0\)</span>, et on calcule la d&#233;riv&#233;e partielle de la fonction <span class="math inline">\(J\)</span> en ce point :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/exemple_simplifie_algo_gradient_init.png" alt="Initialisation" />
<p class="caption">Initialisation</p>
</div>
<p>La d&#233;riv&#233;e partielle est la droite en bleue, et on remarque que le coefficient directeur de la tangente est <strong>n&#233;gatif</strong> et <strong>important</strong>, notre algorithme va donc <strong>augmenter</strong> <span class="math inline">\(\theta_{0}\)</span> de mani&#232;re <strong>importante</strong>.</p>
<p>On peut continuer ainsi jusqu'&#224; tomber sur le minimum de notre fonction :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/exemple_simplifie_algo_gradient_reste.png" alt="Reste de l&#39;algorithme" />
<p class="caption">Reste de l'algorithme</p>
</div>
<p>M&#234;me si on a vu que notre algorithme ne trouvera pas toujours le minimum global de la fonction, un minimum local est toujours int&#233;ressant, et sur des probl&#232;mes tr&#232;s complexes cela sera beaucoup plus efficace &#224; utiliser qu'une approximation faite &#224; la main.</p>
<h2 id="pseudo-code">Pseudo-code</h2>
<p>Maintenant qu'on a vu le principe, il faut le d&#233;crire de mani&#232;re concr&#232;te et math&#233;matique.</p>
<p>Tant que l'algorithme ne converge pas, on met &#224; jour tous nos coefficients <span class="math inline">\(\theta\)</span> pour <span class="math inline">\(j\)</span> allant de 0 &#224; <span class="math inline">\(n\)</span> :</p>
<p><span class="math inline">\(\theta_{j} = \theta_{j} - \alpha\frac{\partial}{\partial\theta_{j}}J(\theta)\)</span></p>
<p><span class="math inline">\(\alpha\)</span> est notre <strong>vitesse d'apprentissage</strong> qui sert &#224; r&#233;guler la rapidit&#233; de la convergence. La d&#233;riv&#233;e partielle de <span class="math inline">\(J\)</span> est repr&#233;sent&#233;e par <span class="math inline">\(\frac{\partial}{\partial\theta_{j}}J(\theta)\)</span>, et lorsqu'on <a href="https://math.stackexchange.com/questions/70728/partial-derivative-in-gradient-descent-for-two-variables/189792#189792">calcule cette d&#233;riv&#233;e</a> on obtient l'expression suivante :</p>
<p><span class="math inline">\(\frac{\partial}{\partial\theta_{j}}J(\theta) = \frac{1}{m}\displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})x_{ij}\)</span></p>
<p>Notre formule d&#233;velopp&#233;e est donc :</p>
<p><span class="math inline">\(\theta_{j} = \theta_{j} - \alpha\frac{1}{m}\displaystyle\sum_{i=1}^{m} (h_{\theta}(x_{i}) - y_{i})x_{ij}\)</span></p>
<p>Dans notre d&#233;tail de l'algorithme du gradient, il y a un point tr&#232;s important &#224; ne pas n&#233;gliger : la mise &#224; jour de mani&#232;re <strong>instantan&#233;e</strong>. Vu que notre expression d&#233;pend elle-m&#234;me de <span class="math inline">\(\theta\)</span>, on ne peut pas se permettre de modifier certaines valeurs lorsqu'on met &#224; jour nos coefficients un &#224; un, il faut donc proc&#233;der en deux &#233;tapes bien distinctes :</p>
<ul>
<li>Mettre &#224; jour nos valeurs en utilisant des variables temporaires.</li>
<li>Copier le contenu de ces variables temporaires dans nos coefficients.</li>
</ul>
<p>Si l'on garde notre exemple avec deux attributs, on aurait ces op&#233;rations &#224; effectuer :</p>
<p><span class="math inline">\(temp0 = \theta_{0} - \alpha\frac{\partial}{\partial\theta_{0}}J(\theta_{0}, \theta_{1})\)</span></p>
<p><span class="math inline">\(temp1 = \theta_{1} - \alpha\frac{\partial}{\partial\theta_{1}}J(\theta_{0}, \theta_{1})\)</span></p>
<p><span class="math inline">\(\theta_{0} = temp0\)</span></p>
<p><span class="math inline">\(\theta_{1} = temp1\)</span></p>
<p>Le pseudo-code d&#233;finitif ressemble donc &#224; ceci :</p>
<pre class="nohighlight"><code>Tant qu&#39;on n&#39;a pas d&#233;pass&#233; la limite de tours
   Pour chaque coefficient
      Calculer temp[j]
   Pour chaque coefficient
      theta[j] = temp[j]</code></pre>
<p>Notre boucle principale n'utilise plus la condition de convergence de notre algorithme du gradient pour plusieurs raisons :</p>
<ul>
<li>Lorsqu'on atteint un minimum local (ou global), l'algorithme va automatiquement s'arr&#234;ter car il ne met plus &#224; jour les coefficients <span class="math inline">\(\theta\)</span> vu que notre tangente sera horizontale.</li>
<li>Il est pr&#233;f&#233;rable de fixer un nombre de tours maximum &#224; l'algorithme car sinon ce dernier peut prendre &#233;norm&#233;ment de temps &#224; converger et il est plus int&#233;ressant de pouvoir contr&#244;ler la dur&#233;e de calcul afin d'&#233;tudier la progression de notre algorithme du gradient.</li>
</ul>
<h2 id="coefficient-dapprentissage">Coefficient d'apprentissage</h2>
<p>Il est primordial de bien choisir le coefficient d'apprentissage, car si <span class="math inline">\(\alpha\)</span> est trop &#233;lev&#233; notre algorithme va chercher &#224; faire de tr&#232;s grands pas afin de converger rapidement (en anglais on utilise le terme de <em>overshoot</em>), et ceci peut l'amener &#224; faire de mauvais choix comme par exemple :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/exemple_coeff_apprentissage_eleve.png" alt="Exemple de cons&#233;quence d&#39;un coefficient d&#39;apprentissage &#233;lev&#233;" />
<p class="caption">Exemple de cons&#233;quence d'un coefficient d'apprentissage &#233;lev&#233;</p>
</div>
<p>L'algorithme risque alors de ne pas converger voire de <strong>diverger</strong>.</p>
<p>A l'inverse, une vitesse d'apprentissage trop faible rendra notre algorithme terriblement lent :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/exemple_coeff_apprentissage_faible.png" alt="Exemple de cons&#233;quence d&#39;un coefficient d&#39;apprentissage faible" />
<p class="caption">Exemple de cons&#233;quence d'un coefficient d'apprentissage faible</p>
</div>
<p>Pour choisir une valeur adapt&#233;e &#224; notre probl&#232;me, il faut en essayer diff&#233;rentes (0.001, 0.01, 0.1, 1, 10, etc.) tout en cr&#233;ant un graphique repr&#233;sentant l'&#233;volution de notre minimisation de <span class="math inline">\(J\)</span> en fonction du nombre d'it&#233;rations de l'algorithme. Si vous avez bien choisi le coefficient, vous devriez voir un graphique semblable &#224; ceci :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/exemple_coeff_apprentissage_bon.png" alt="Exemple de coefficient adapt&#233;" />
<p class="caption">Exemple de coefficient adapt&#233;</p>
</div>
<p>On remarque bien que notre algorithme minimise bien la fonction d'erreur au fur et &#224; mesure qu'il it&#232;re, ce qui signifie que notre vitesse d'apprentissage est adapt&#233;e &#224; notre probl&#232;me.</p>
<h2 id="impl&#233;mentation">Impl&#233;mentation</h2>
<p>Voici le code en Python pour l'algorithme du gradient :</p>
<p><em>J'utilise Python afin d'avoir acc&#232;s &#224; des librairies scientifiques comme <a href="http://www.numpy.org/">numpy</a> pour les matrices et <a href="http://matplotlib.org/">matplotlib</a> pour les graphiques.</em></p>
<a href="javascript:toggle_visibility('regression_lineaire.py');">regression_lineaire.py</a>
<div id="regression_lineaire.py" style="display: none;">
<pre class="py"><code>import numpy as np


# x = exemple d&#39;entr&#233;e
# y = exemple de sortie
# m = nombre d&#39;exemples
# n = nombre d&#39;attributs
# theta = coefficients de notre fonction d&#39;hypothese

class regression_lineaire:

    def __init__(self, entree):
        with open(entree) as f:
            self.m, self.n = map(int, f.readline().split())

        self.x = np.matrix(np.loadtxt(entree, skiprows=1,
                            usecols=(list(range(self.n))), ndmin=2))
        self.y = np.matrix(np.loadtxt(entree, skiprows=1,
                            usecols=([self.n]), ndmin=2))

        # Ajoute une colonne de 1 au d&#233;but de notre matrice x
        col = np.ones((self.m, 1))
        self.x = np.matrix(np.hstack((col, self.x)))
        self.n = self.n + 1

        # Initialise &#224; 0 les coefficients de la fonction d&#39;hypothese
        self.theta = np.matrix(np.zeros((self.n, 1)))

    def algo_gradient(self, alpha, nb_tour_max):
        for _ in range(nb_tour_max):
            # Pour faire la mise &#224; jour instantan&#233;e des coefficients :
            # 1. On calcule d&#39;abord les r&#233;sultats dans des variables temporaires
            temp = np.zeros((self.n, 1))
            for j in range(self.n):
                somme = 0.0
                for i in range(self.m):
                    hypothese = float(self.x[i] * self.theta)
                    somme = somme + ((hypothese - self.y[i]) * self.x.item((i, j)))
                temp[j] = self.theta[j] - alpha * (1 / self.m) * somme

            # 2. Puis on copie les r&#233;sultats dans nos coefficients
            for j in range(self.n):
                self.theta[j] = temp[j]


ia = regression_lineaire(&quot;test01.in&quot;)
ia.algo_gradient(0.01, 400)

print(&quot;Coefficients de la fonction d&#39;hypothese :\n&quot;)
for j in range(ia.n):
    print(&quot;theta &quot;, j, &quot; : &quot;, float(ia.theta[j]))</code></pre>
</div>
<p>Notre fichier d'entr&#233;e contient sur la premi&#232;re ligne le nombre <span class="math inline">\(m\)</span> d'exemples, puis le nombre <span class="math inline">\(n\)</span> d'attributs. Sur les <span class="math inline">\(m\)</span> prochaines lignes, on retrouve une liste de nombre dont la derni&#232;re colonne correspond &#224; <span class="math inline">\(y\)</span> et les autres &#224; <span class="math inline">\(x\)</span>. J'ai repris notre exemple de l'introduction pour construire le fichier d'entr&#233;e (les unit&#233;s sont toujours en centaine d'op&#233;rations et en centaine d'euros) :</p>
<pre class="nohighlight"><code>6 1
1.73 1.94
4.07 2.87
5.34 5.01
7.14 6.74
9.56 7.71
12.26 8.6</code></pre>
<p>En sortie on obtient les coefficients <span class="math inline">\(\theta\)</span> de notre fonction d'hypoth&#232;se :</p>
<pre class="nohighlight"><code>Coefficients de la fonction d&#39;hypothese :

theta  0  :  0.5764647547614207
theta  1  :  0.7219164912370313</code></pre>
<p>Vu qu'on a uniquement un attribut (la puissance d'un ordinateur), on peut repr&#233;senter notre fonction d'hypoth&#232;se et nos donn&#233;es en entr&#233;e sur un graphique 2D :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/sortie_prog_algo_gradient.png" alt="Sortie graphique du programme" />
<p class="caption">Sortie graphique du programme</p>
</div>
<p>On obtient bien une g&#233;n&#233;ralisation efficace sous forme de fonction lin&#233;aire qui ressemble fortement &#224; celle qu'un humain peut faire &#224; la main (m&#234;me si celle que l'ordinateur a calcul&#233; est plus pr&#233;cise que celle faite &#224; la main).</p>
<p>Le code utilis&#233; pour r&#233;aliser cette sortie :</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt

<span class="co"># R&#233;cup&#232;re dans des listes les valeurs de x, y, et de notre approximation de y</span>
x <span class="op">=</span> np.array(ia.x[:,<span class="dv">1</span>]).tolist()
x <span class="op">=</span> [<span class="bu">float</span>(i[<span class="dv">0</span>]) <span class="cf">for</span> i <span class="op">in</span> x]

y <span class="op">=</span> np.array(ia.y).tolist()
y <span class="op">=</span> [<span class="bu">float</span>(i[<span class="dv">0</span>]) <span class="cf">for</span> i <span class="op">in</span> y]

y_approx <span class="op">=</span> np.array(ia.x <span class="op">*</span> ia.theta).tolist()
y_approx <span class="op">=</span> [<span class="bu">float</span>(i[<span class="dv">0</span>]) <span class="cf">for</span> i <span class="op">in</span> y_approx]

<span class="co"># Affiche les points donn&#233;s en entr&#233;e, ainsi que notre mod&#232;le lin&#233;aire</span>
plt.plot(x, y, <span class="st">&#39;+&#39;</span>)
plt.plot(x, y_approx, <span class="st">&#39;r-&#39;</span>)
plt.show()</code></pre></div>
<h2 id="am&#233;liorations">Am&#233;liorations</h2>
<h3 id="vectorization"><em>Vectorization</em></h3>
<p>Afin de simplifier le code, il serait utile d'utiliser la m&#234;me am&#233;lioration qu'avec notre fonction d'hypoth&#232;se : l'utilisation d'op&#233;rations sur les matrices. Au lieu d'appliquer des op&#233;rations sur les &#233;l&#233;ments d'une matrice un par un, on peut utiliser des op&#233;rations plus g&#233;n&#233;rales sur notre matrice enti&#232;re. Cela permet de supprimer la plupart des boucles, mais aussi, a le gros avantage de r&#233;aliser une mise &#224; jour instantan&#233;e des coefficients automatiquement, sans m&#234;me avoir besoin de stocker nos r&#233;sultats dans des variables temporaires. On peut donc transformer notre algorithme du gradient en ceci :</p>
<p><span class="math inline">\(\theta = \theta - \alpha\frac{1}{m}x^\intercal(h_{\theta}(x) - y)\)</span></p>
<p>Si on d&#233;veloppe notre fonction d'hypoth&#232;se on arrive &#224; cette expression :</p>
<p><span class="math inline">\(\theta = \theta - \alpha\frac{1}{m}x^\intercal(x\theta - y)\)</span></p>
<p>Il n'y a plus aucunes boucles, et uniquement des op&#233;rations matricielles. Notre fonction pour l'algorithme du gradient devient donc dans notre code :</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> algo_gradient(<span class="va">self</span>, alpha, nb_tour_max):
   <span class="cf">for</span> _ <span class="op">in</span> <span class="bu">range</span>(nb_tour_max):
      derivee <span class="op">=</span> np.transpose(<span class="va">self</span>.x) <span class="op">*</span> (<span class="va">self</span>.x <span class="op">*</span> <span class="va">self</span>.theta <span class="op">-</span> <span class="va">self</span>.y)
      <span class="va">self</span>.theta <span class="op">=</span> <span class="va">self</span>.theta <span class="op">-</span> alpha <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> <span class="va">self</span>.m) <span class="op">*</span> derivee</code></pre></div>
<p>Le code est beaucoup plus concis de cette mani&#232;re, ce qui rend sa lecture plus facile et agr&#233;able.</p>
<h3 id="feature-scaling"><em>Feature scaling</em></h3>
<p>Dans le cas de g&#233;n&#233;ralisation d'un probl&#232;me avec plusieurs attributs, il est possible que l'&#233;chelle de valeurs possibles soit tr&#232;s diff&#233;rente d'un attribut &#224; un autre. Par exemple, dans l'estimation du prix d'un ordinateur, le nombre d'op&#233;rations que l'ordinateur effectue &#224; la seconde repr&#233;sente un nombre bien plus important que le nombre de ventilateurs &#224; l'int&#233;rieur de la machine. Si on affiche un <em>contour plot</em> dans cette situation, on verrait ce ph&#233;nom&#232;ne :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/echelles_differentes.png" alt="Echelles diff&#233;rentes au sein des attributs" />
<p class="caption">Echelles diff&#233;rentes au sein des attributs</p>
</div>
<p>Le probl&#232;me ici est que notre algorithme du gradient va mettre beaucoup plus de temps &#224; converger vers un minimum, car on a de longs et fins contours. A l'inverse, si on arrive &#224; rendre les &#233;chelles similaires, on aurait plut&#244;t un graphique qui ressemble &#224; cela :</p>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/echelles_similaires.png" alt="Echelles similaires" />
<p class="caption">Echelles similaires</p>
</div>
<p>Notre algorithme va alors converger bien plus rapidement.</p>
<p>Pour r&#233;aliser cette op&#233;ration dite de <a href="https://en.wikipedia.org/wiki/Feature_scaling"><em>feature scaling</em></a> en anglais, on utilise une m&#233;thode de <a href="https://en.wikipedia.org/wiki/Feature_scaling#Standardization">standardisation</a> (aussi appel&#233;e <em>mean normalization</em>). Le but est d'avoir toutes nos valeurs de <span class="math inline">\(x\)</span>, tel qu'on a approximativement <span class="math inline">\(-1 \leq x \leq 1\)</span>. On va donc modifier chaque valeur <span class="math inline">\(i\)</span> de <span class="math inline">\(x\)</span> de cette fa&#231;on :</p>
<p><span class="math inline">\(x_i = \frac{x_i - \bar{x_i}}{\sigma_i}\)</span></p>
<p><span class="math inline">\(\bar{x}\)</span> repr&#233;sente la moyenne, et <span class="math inline">\(\sigma\)</span> est l'<a href="https://fr.wikipedia.org/wiki/%C3%89cart_type">&#233;cart type</a> (qui nous sert &#224; mesurer la dispersion de nos valeurs).</p>
<p>Il faut en revanche faire attention &#224; ne pas appliquer cela sur <span class="math inline">\(x_0\)</span> car cette valeur doit toujours &#234;tre &#233;gale &#224; 1, on r&#233;alisera donc l'op&#233;ration de feature scaling avant d'ajouter notre colonne de 1 &#224; <span class="math inline">\(x\)</span> :</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Feature scaling</span>
<span class="va">self</span>.x <span class="op">=</span> (<span class="va">self</span>.x <span class="op">-</span> np.mean(<span class="va">self</span>.x)) <span class="op">/</span> np.std(<span class="va">self</span>.x)</code></pre></div>
<p>Notre sortie n'est alors plus la m&#234;me puisque nos valeurs ont &#233;t&#233; chang&#233; pour &#234;tre sur une &#233;chelle similaire :</p>
<pre class="nohighlight"><code>Coefficients de la fonction d&#39;hypothese :

theta  0  :  5.379994218974877
theta  1  :  2.3208884389927897</code></pre>
<div class="figure">
<img src="//static.napnac.ga/img/algo/ia/apprentissage_artificiel/regression_lineaire/algo_gradient/sortie_prog_feature_scaling.png" alt="Sortie graphique apr&#232;s op&#233;ration de feature scaling" />
<p class="caption">Sortie graphique apr&#232;s op&#233;ration de feature scaling</p>
</div>
<p>Le code final avec les deux am&#233;liorations :</p>
<a href="javascript:toggle_visibility('regression_lineaire_vect_fs.py');">regression_lineaire_vect_fs.py</a>
<div id="regression_lineaire_vect_fs.py" style="display: none;">
<pre class="py"><code>import numpy as np


# x = exemple d&#39;entr&#233;e
# y = exemple de sortie
# m = nombre d&#39;exemples
# n = nombre d&#39;attributs
# theta = coefficients de notre fonction d&#39;hypothese

class regression_lineaire:

    def __init__(self, entree):
        with open(entree) as f:
            self.m, self.n = map(int, f.readline().split())

        self.x = np.matrix(np.loadtxt(entree, skiprows=1,
                            usecols=(list(range(self.n))), ndmin=2))
        self.y = np.matrix(np.loadtxt(entree, skiprows=1,
                            usecols=([self.n]), ndmin=2))

        # Feature scaling
        self.x = (self.x - np.mean(self.x)) / np.std(self.x)

        # Ajoute une colonne de 1 au d&#233;but de notre matrice x
        col = np.ones((self.m, 1))
        self.x = np.matrix(np.hstack((col, self.x)))
        self.n = self.n + 1

        # Initialise &#224; 0 les coefficients de la fonction d&#39;hypothese
        self.theta = np.matrix(np.zeros((self.n, 1)))

    def algo_gradient(self, alpha, nb_tour_max):
        for _ in range(nb_tour_max):
            derivee = np.transpose(self.x) * (self.x * self.theta - self.y)
            self.theta = self.theta - alpha * (1 / self.m) * derivee


ia = regression_lineaire(&quot;test01.in&quot;)
ia.algo_gradient(0.01, 400)

print(&quot;Coefficients de la fonction d&#39;hypothese :\n&quot;)
for j in range(ia.n):
    print(&quot;theta &quot;, j, &quot; : &quot;, float(ia.theta[j]))</code></pre>
</div>
<h2 id="conclusion">Conclusion</h2>
 
      <!-- ------------ -->

      <footer>
         <hr>
         <p>Une question ? Une suggestion ? N'h&#233;sitez pas &#224; me <a href="/a_propos.html">contacter</a> pour me communiquer vos remarques.
         <br>
      </footer>

   </body>
</html>

<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

        <link rel="stylesheet" type="text/css" href="/css/base.css">
        <link rel="icon" type="image/x-icon" href="/img/favicon.ico">

        <!-- Font Awesome -->
        <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

        <!-- Syntax highlighting -->
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>
        <link rel="stylesheet" type="text/css" href="/css/highlight_theme.css">
        <script>hljs.highlightAll();</script>

        <!-- Renders LaTeX expression -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']], processEscapes: true}});
        </script>
        <script type="text/javascript" async 
                src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML">
        </script>

        <title>March</title>

    </head>

    <body>
        <header>
    <nav>
        <ul>
            <li><a href="/">Thibault Allan√ßon</a></li>
            <li><a href="/gsoc2019.html">GSoC 2019</a></li>
        </ul>
    </nav>

    <h1><a href="">March</a></h1>

        </header>


        <h2 id="pre-application-period">Pre-application period</h2>
<p>The goal was to become more familiar with SWH infrastructure, code
review and the community. I joined the IRC channel #swh-devel and the <a
href="https://sympa.inria.fr/sympa/info/swh-devel">mailing list</a> and
started working on getting the SWH development setup running. I focused
on the "Easy hacks" tasks (<a
href="https://forge.softwareheritage.org/D1226">D1226</a>, <a
href="https://forge.softwareheritage.org/D1235">D1235</a>) and
documentation fixes (<a
href="https://forge.softwareheritage.org/D1217">D1217</a>, <a
href="https://forge.softwareheritage.org/D1242">D1242</a>) at first,
before studying more in depth the subject I chose: <a
href="https://wiki.softwareheritage.org/wiki/Graph_compression_on_the_development_history_of_software_(internship)">Graph
compression on the development history of software</a>. This allowed me
to experiment for a bit with the SWH codebase, run tests environment,
solve some issues, and talk with SWH staffers!</p>
<p>I contacted the mentor for the subject early, and sent my resume. He
quickly got back to me, and gave me papers to read on graph compression
techniques:</p>
<ul>
<li><a href="http://www.web.ethz.ch/CDstore/www2004/docs/1p595.pdf">The
WebGraph Framework I: Compression Techniques</a></li>
<li><a href="https://arxiv.org/pdf/1011.5425">Layered Label Propagation:
A MultiResolution Coordinate-Free Ordering for Compressing Social
Networks</a></li>
</ul>
<p>They already had some early results, thanks to Boldi &amp; Vigna (the
authors of the WebGraph framework/paper) and I tried replicating it on
my own laptop. Unfortunately, I only have 8GB of RAM so running Java
programs to compress big files quickly gets OOM killed.</p>
<p>My mentor told me he can maybe give me access to a VM so I could run
my experiments, in the meantime I automated the setup process and
testing using Docker and a bash script to retrieve datasets and compress
them using WebGraph.</p>
<details>
<summary>Dockerfile</summary>
<pre><code class="docker">FROM maven:3.6.0-jdk-8
WORKDIR /app

# Download webgraph binary
RUN curl -O http://webgraph.di.unimi.it/webgraph-3.6.1-bin.tar.gz
RUN tar xvfz webgraph-3.6.1-bin.tar.gz
RUN cp webgraph-3.6.1/webgraph-3.6.1.jar .

# Download webgraph dependencies
RUN curl -O http://webgraph.di.unimi.it/webgraph-deps.tar.gz
RUN tar xvfz webgraph-deps.tar.gz

# Download missing LAW dependency
RUN curl -O http://law.di.unimi.it/software/download/law-2.5-bin.tar.gz
RUN tar xvfz law-2.5-bin.tar.gz
RUN cp law-2.5/law-2.5.jar .

WORKDIR /graph
COPY compress_graph .</code></pre>
</details>
<details>
<summary>compress_graph</summary>
<pre><code class="bash">#!/bin/bash

DATASET=release_to_obj

# Download the edge list
curl -O https://annex.softwareheritage.org/public/dataset/swh-graph-2019-01-28/edges/$DATASET.csv.gz
# Uncompress the edge list
gunzip $DATASET.csv.gz
# Compute the node list
tr &#39; &#39; &#39;\n&#39; &lt;$DATASET.csv | sort -u &gt;$DATASET.nodes

# Build a function (MPH) that maps node names to node numbers in lexicographic order (output: $DATASET.mph)
java -cp /app/&#39;*&#39; it.unimi.dsi.sux4j.mph.GOVMinimalPerfectHashFunction $DATASET.mph /data/$DATASET.nodes

# Build the graph in BVGraph format (output: $DATASET.*)
java -cp /app/&#39;*&#39; it.unimi.dsi.webgraph.ScatteredArcsASCIIGraph -f $DATASET.mph $DATASET &lt;/data/$DATASET.csv

# Create a symmetrized version of the graph (output: $DATASET-s.*)
java -cp /app/&#39;*&#39; it.unimi.dsi.webgraph.Transform symmetrizeOffline $DATASET $DATASET-s

# Find a better permutation through Layered LPA (output: $DATASET.llpa)
java -cp /app/&#39;*&#39; it.unimi.dsi.law.graph.LayeredLabelPropagation $DATASET-s $DATASET.llpa

# Permute the graph accordingly (output: $DATASET-compr.*)
java -cp /app/&#39;*&#39; it.unimi.dsi.webgraph.Transform mapOffline $DATASET $DATASET-compr $DATASET.llpa

# Compute graph statistics (output: $DATASET.stats)
java -cp /app/&#39;*&#39; it.unimi.dsi.webgraph.Stats -s $DATASET

# Clean up the current directory
mkdir $DATASET
mv $DATASET.* $DATASET
mv $DATASET-s.* $DATASET
mv $DATASET-compr.* $DATASET</code></pre>
</details>
<p>I also took the time to dive more into research papers and SWH
infrastructure:</p>
<ul>
<li><a
href="https://hal.archives-ouvertes.fr/hal-01590958/document">Software
Heritage: Why and How to Preserve Software Source Code</a></li>
<li>The Software Heritage Graph Dataset: Public software development
under one roof</li>
<li><a
href="https://docs.softwareheritage.org/devel/">https://docs.softwareheritage.org/devel/</a></li>
<li><a
href="https://docs.softwareheritage.org/devel/glossary.html">https://docs.softwareheritage.org/devel/glossary.html</a></li>
<li><a
href="https://wiki.softwareheritage.org/wiki/Special:AllPages">https://wiki.softwareheritage.org/wiki/Special:AllPages</a></li>
<li><a href="https://people.csail.mit.edu/jshun/ligra+.pdf">Smaller and
Faster: Parallel Processing of Compressed Graphs with Ligra+</a></li>
<li><a
href="http://www2.aueb.gr/users/katia/publications/LPDcikm2016-preprint.pdf">Memory-Optimized
Distributed Graph Processing through Novel Compression
Techniques</a></li>
<li><a href="http://www.cs.cornell.edu/~ragarwal/pubs/zipg.pdf">ZipG: A
Memory-efficient Graph Store for Interactive Queries</a></li>
<li>An effective graph summarization and compression technique for a
large-scaled grap</li>
<li><a href="https://kowshik.github.io/JPregel/pregel_paper.pdf">Pregel:
A System for Large-Scale Graph Processing</a></li>
<li><a href="https://arxiv.org/pdf/1612.04883.pdf">Graph Summarization
Methods and Applications: A Survey</a></li>
<li><a
href="http://www.textfiles.com/bitsavers/pdf/dec/tech_reports/SRC-RR-175.pdf">The
Link Database: fast access to graphs of the Web</a></li>
<li><a href="https://www.mdpi.com/1999-4893/2/3/1031/pdf">Graph
Compression by BFS</a></li>
</ul>
<p>A few days before the official application period, I begin writing
mine to get early feedbacks once the deadline hits. Here is the final
pdf: <a
href="https://haltode.fr/static/proposal.pdf">proposal.pdf</a>.</p>
<h2 id="application-period-part-1">Application period (part 1)</h2>
<p>My mentor gave me access to a first VM with 140GB of RAM and 72vCPUs
so I could do some early experiments. But I quickly got limited by the
disk space (first time I have more RAM than disk space :D), so they gave
me access to another VM. A <strong>beefy</strong> one: 2TB RAM and
128vCPUs with 1TB of disk storage (for 2 weeks)!</p>
<p>In the same time, they heard about a new reference paper on the graph
compression problem: <a
href="https://arxiv.org/pdf/1602.08820.pdf">Compressing Graphs and
Indexes with Recursive Graph Bisection</a>. I went through it quickly
but from their paper: "we do not release the datasets and our source
code due to corporate restrictions". Couldn't find an open source
implementation, I contacted the author to have insights on such
implementation but didn't get any response.</p>
<p>Back to the WebGraph framework, I tried using the -big version
(64bit) since some parts of the DAG contain billions of nodes/edges, but
I ran into a runtime exception. To get some results I used the 32bit
version to see if I still had this exception. The process ran fine but
it was <strong>really</strong> slow, and as I contacted the authors of
the WebGraph framework they pointed out a useless redirection that was
intensely slowing down the process (because of swapping).</p>
<p>It's time to gather some data now!</p>



        <footer>
        </footer>
    </body>
</html>